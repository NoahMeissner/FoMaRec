{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8bb5a1",
   "metadata": {},
   "source": [
    "## Normalization Ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894e468",
   "metadata": {},
   "source": [
    "Noah Meissner 11.06.2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bd90a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noah/Documents/github/MultiAgentBiase/Preprocessing/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data_structure.paths import RAW_SET, NER_EVAL\n",
    "from DataLoader_Ingredients import DataLoader\n",
    "from request.recipe_api import request_api\n",
    "from normalizer.normalizer import Normalization\n",
    "from loader.load_normalization import save_response\n",
    "from data_structure.model_name import ModelName\n",
    "from data_structure.DataType import DataType\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed717ff",
   "metadata": {},
   "source": [
    "### Take Dataset\n",
    "- The following function loads the dataset and gives unique ingreidents as test and train split\n",
    "- Train 50000\n",
    "- Test 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b33011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole = pd.read_csv(RAW_SET)\n",
    "loader_obj = DataLoader(df_whole)\n",
    "train, test = loader_obj.get_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4e5a8",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "we now analyse our approach, using Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4d89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Grafik wie er funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f7aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_request(txt):\n",
    "    output = request_api(txt)\n",
    "    detailed_info = output.get(\"detailed_info\", [])\n",
    "    \n",
    "    if detailed_info and len(detailed_info) > 0 and detailed_info[0] and len(detailed_info[0]) > 0:\n",
    "        erkannte_zutat = [detailed_info[0][0].get(\"erkannteZutat\", \"\")]\n",
    "    else:\n",
    "        erkannte_zutat = [] \n",
    "    \n",
    "    return erkannte_zutat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb1cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingredients(txt):\n",
    "    if txt is None:\n",
    "        return \"\"\n",
    "    txt = txt.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\"%x22\",\"\").strip()\n",
    "    txt = re.sub(r\"\\s+\",\" \", txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722174cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/noah/Documents/github/MultiAgentBiase/Preprocessing/model/modern_bert/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalize Data:   0%|          | 0/1000 [00:00<?, ?it/s]Compiling the model with `torch.compile` and using a `torch.cpu` device is not supported. Falling back to non-compiled mode.\n",
      "Normalize Data: 100%|██████████| 1000/1000 [15:29<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "normalisation = Normalization()\n",
    "ls_res = []\n",
    "equal = 0\n",
    "under = 0\n",
    "over = 0\n",
    "zero = 0\n",
    "ls_api = []\n",
    "for ingredient in tqdm(test, desc=\"Normalize Data\"):\n",
    "    ingredient = clean_ingredients(ingredient)\n",
    "    original_class = api_request(ingredient)\n",
    "    pipeline_ingredient, len_ingredients = normalisation.normalize(ingredient)\n",
    "    # Calc Stats for ONLY API\n",
    "    if len(original_class) > 0 and original_class[0] != \"Nicht erkannt\":\n",
    "        equal += int(len(original_class) == len_ingredients)\n",
    "        under += int(len(original_class) < len_ingredients)\n",
    "        over += int(len(original_class) > len_ingredients)\n",
    "    zero += int(len(original_class) == 0)\n",
    "    ############\n",
    "    ls_res.append(pipeline_ingredient)\n",
    "    ls_api.append({ingredient : original_class})\n",
    "save_response(ModelName.UNI,DataType.eval,ls_api)\n",
    "save_response(ModelName.Pipeline,DataType.eval,ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f2d76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'equal': 345, 'under': 12, 'over': 4, 'zero': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"equal\": equal, \"under\": under, \"over\": over, \"zero\":zero}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b57f731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'equal': 679, 'under': 321, 'over': 0, 'zero': 321}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalisation.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab85206",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline_wrong = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c96211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/noah/Documents/github/MultiAgentBiase/Preprocessing/model/modern_bert/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model with `torch.compile` and using a `torch.cpu` device is not supported. Falling back to non-compiled mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['200', 'Number'], ['g', 'Units'], [' Mehl', 'Ingredients']]\n",
      "{'original': '200g Mehl', 'ner': {'200g Mehl': {'entities': [['200', 'Number'], ['g', 'Units'], [' Mehl', 'Ingredients']]}}}\n"
     ]
    }
   ],
   "source": [
    "norm = Normalization()\n",
    "norm.tokenize(\"200g Mehl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159e27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
