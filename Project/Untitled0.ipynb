{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d8b72a8e49c4a46b6bb1e908907bc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4184180cd4204b759e2ca0dbef38d681",
              "IPY_MODEL_8d1b333767564a0997c12ffdd326a37f",
              "IPY_MODEL_597e8cb365c348249c6ad50cfc34fed1"
            ],
            "layout": "IPY_MODEL_0a7ccdf91c7a4362a77f7ed544d58517"
          }
        },
        "4184180cd4204b759e2ca0dbef38d681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2f9deaa4d94862b245744718c76b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0a6382c3a042c192fb954c29c3ee4a",
            "value": "Map: 100%"
          }
        },
        "8d1b333767564a0997c12ffdd326a37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66077eef4d1c4bc2b759b10c2189a2f8",
            "max": 9204,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d16fce3eefe64ad7b8adbf6b1b8be323",
            "value": 9204
          }
        },
        "597e8cb365c348249c6ad50cfc34fed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27b8e638a8a449d9c621d5961a36a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_49a77a590d364439944114495cc9170d",
            "value": " 9204/9204 [00:01&lt;00:00, 5488.92 examples/s]"
          }
        },
        "0a7ccdf91c7a4362a77f7ed544d58517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2f9deaa4d94862b245744718c76b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0a6382c3a042c192fb954c29c3ee4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66077eef4d1c4bc2b759b10c2189a2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d16fce3eefe64ad7b8adbf6b1b8be323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c27b8e638a8a449d9c621d5961a36a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a77a590d364439944114495cc9170d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLle1ReVDsMW",
        "outputId": "beebd2d2-ea3c-498b-fc88-e1e0052b4d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install seqeval"
      ],
      "metadata": {
        "id": "7v1Ppq8P2Alz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('Gemini.json' , 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "vcOReXHsKMMr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bio_labels(tokens, offsets, spans):\n",
        "    labels = [\"O\"] * len(tokens)\n",
        "    for start, end, label in spans:\n",
        "        for i, (tok_start, tok_end) in enumerate(offsets):\n",
        "            if tok_start >= start and tok_end <= end:\n",
        "                if tok_start == start:\n",
        "                    labels[i] = f\"B-{label}\"\n",
        "                else:\n",
        "                    labels[i] = f\"I-{label}\"\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "AAoxMHiVEGxg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Labels = ['O', 'B-Ingredients', 'I-Ingredients', 'B-Number', 'I-Number', 'B-Type', 'I-Type', 'B-Units', 'I-Units']\n",
        "label2id = {'O': 0, 'B-Ingredients': 1, 'I-Ingredients': 2, 'B-Number': 3, 'I-Number': 4, 'B-Type': 5, 'I-Type': 6, 'B-Units': 7, 'I-Units': 8}\n",
        "id2label = {0: 'O', 1: 'B-Ingredients', 2: 'I-Ingredients', 3: 'B-Number', 4: 'I-Number', 5: 'B-Type', 6: 'I-Type', 7: 'B-Units', 8: 'I-Units'}\n",
        "\n",
        "def calc_tokens(text, entities):\n",
        "    spans = []\n",
        "    try:\n",
        "      for ent_text, ent_label in entities:\n",
        "          start = text.find(ent_text)\n",
        "          end = start + len(ent_text)\n",
        "          spans.append((start, end, ent_label))\n",
        "\n",
        "      encoding = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "      tokens = encoding.tokens()\n",
        "      offsets = encoding.offset_mapping\n",
        "\n",
        "      labels = get_bio_labels(tokens, offsets, spans)\n",
        "      entity = [value[0] for value in entities]\n",
        "      label = [label2id[value] for value in labels]\n",
        "      return {\"tokens\":tokens, \"ner_tags\":label}\n",
        "    except Exception as e:\n",
        "      return None"
      ],
      "metadata": {
        "id": "phQ5w6UkKb9g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "for example in data:\n",
        "    text = list(example.keys())[0]\n",
        "    values = list(example.values())\n",
        "    entities = values[0]['entities']\n",
        "    dataset.append(calc_tokens(text, entities))"
      ],
      "metadata": {
        "id": "vbQ9vavXLtOG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=32\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "ASHeJY8OPKmq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset = Dataset.from_list([d for d in dataset if d is not None])"
      ],
      "metadata": {
        "id": "1Mg75cUlNPg7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = hf_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=hf_dataset.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3d8b72a8e49c4a46b6bb1e908907bc3a",
            "4184180cd4204b759e2ca0dbef38d681",
            "8d1b333767564a0997c12ffdd326a37f",
            "597e8cb365c348249c6ad50cfc34fed1",
            "0a7ccdf91c7a4362a77f7ed544d58517",
            "0f2f9deaa4d94862b245744718c76b4a",
            "fa0a6382c3a042c192fb954c29c3ee4a",
            "66077eef4d1c4bc2b759b10c2189a2f8",
            "d16fce3eefe64ad7b8adbf6b1b8be323",
            "c27b8e638a8a449d9c621d5961a36a0e",
            "49a77a590d364439944114495cc9170d"
          ]
        },
        "id": "pPhtpe57POu6",
        "outputId": "c8e1c59e-3009-4ce0-9492-0484649acfbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9204 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d8b72a8e49c4a46b6bb1e908907bc3a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "dataset_dict = DatasetDict({\n",
        "    \"train\": split_dataset[\"train\"],\n",
        "    \"validation\": split_dataset[\"test\"]\n",
        "})"
      ],
      "metadata": {
        "id": "qY8QsUmBNzMB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-german-cased\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "label2id = {'O': 0, 'B-Ingredients': 1, 'I-Ingredients': 2, 'B-Number': 3, 'I-Number': 4, 'B-Type': 5, 'I-Type': 6, 'B-Units': 7, 'I-Units': 8}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j6RsTjPN0lW",
        "outputId": "16c5687c-e659-4719-b195-b60be9fcd0b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = predictions.argmax(axis=-1)\n",
        "\n",
        "    true_labels = []\n",
        "    true_predictions = []\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        true_label = []\n",
        "        true_pred = []\n",
        "        for p_, l_ in zip(pred, label):\n",
        "            if l_ != -100:\n",
        "                true_label.append(id2label[l_])\n",
        "                true_pred.append(id2label[p_])\n",
        "        true_labels.append(true_label)\n",
        "        true_predictions.append(true_pred)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(true_labels, true_predictions),\n",
        "        \"recall\": recall_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions)\n",
        "    }"
      ],
      "metadata": {
        "id": "a2CuRFMk1x_w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "U_kvPqCjN3VI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_dict[\"train\"],\n",
        "    eval_dataset=dataset_dict[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5cax3kkN9ar",
        "outputId": "d7fd80e5-e923-486a-a21f-49a7c224b915"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-a0ba24eb6ea3>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "6IHDCxdXOCO2",
        "outputId": "92860d99-d75b-470c-df0d-00430be572f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1844' max='1844' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1844/1844 04:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.107800</td>\n",
              "      <td>0.216867</td>\n",
              "      <td>0.920489</td>\n",
              "      <td>0.933248</td>\n",
              "      <td>0.926825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.129500</td>\n",
              "      <td>0.229818</td>\n",
              "      <td>0.919914</td>\n",
              "      <td>0.934343</td>\n",
              "      <td>0.927072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.059200</td>\n",
              "      <td>0.260711</td>\n",
              "      <td>0.918097</td>\n",
              "      <td>0.936349</td>\n",
              "      <td>0.927133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.031500</td>\n",
              "      <td>0.275636</td>\n",
              "      <td>0.921780</td>\n",
              "      <td>0.937078</td>\n",
              "      <td>0.929366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1844, training_loss=0.09491186304555281, metrics={'train_runtime': 273.3597, 'train_samples_per_second': 107.741, 'train_steps_per_second': 6.746, 'total_flos': 481012444664064.0, 'train_loss': 0.09491186304555281, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(text, model, tokenizer, id2label):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_offsets_mapping=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in encoding.items() if k != \"offset_mapping\"}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=2)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"][0])\n",
        "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    reconstructed = reconstruct_tokens(tokens, predicted_labels)\n",
        "    print(f\"\\n{'Wort':<20} | Label\")\n",
        "    print(\"-\" * 35)\n",
        "    for word, label in reconstructed:\n",
        "        print(f\"{word:<20} | {label}\")\n",
        "\n",
        "\n",
        "test_model(\"3 Eier\", model, tokenizer, id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2FLDoWX12yu",
        "outputId": "80476b9e-533a-4778-ea27-5a1846b405c7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wort                 | Label\n",
            "-----------------------------------\n",
            "3                    | O\n",
            "Eier                 | B-Units\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_tokens(tokens, labels):\n",
        "    words = []\n",
        "    word_labels = []\n",
        "\n",
        "    current_word = \"\"\n",
        "    current_label = \"\"\n",
        "\n",
        "    for token, label in zip(tokens, labels):\n",
        "        if token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
        "            continue\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            if current_word:\n",
        "                words.append(current_word)\n",
        "                word_labels.append(current_label)\n",
        "            current_word = token\n",
        "            current_label = label\n",
        "\n",
        "    if current_word:\n",
        "        words.append(current_word)\n",
        "        word_labels.append(current_label)\n",
        "\n",
        "    return list(zip(words, word_labels))\n"
      ],
      "metadata": {
        "id": "V8Z8-t0U5AsP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "bVspQVbt6J_L",
        "outputId": "946d6ab9-50b1-4c8b-b8a2-4804f835230c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'BertForTokenClassification' object has no attribute 'save'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-fa0f59a2410b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BertForTokenClassification' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeuLvdhJFkhb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}