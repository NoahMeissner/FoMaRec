{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f78d0c0",
   "metadata": {},
   "source": [
    "# Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa66f8",
   "metadata": {},
   "source": [
    "Noah Meissner 01.09.2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab7b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from foodrec.utils.search.request_information_extraction import extract_information\n",
    "from foodrec.config.structure.paths import DATASET_PATHS\n",
    "from foodrec.config.structure.dataset_enum import ModelEnum\n",
    "from tqdm import tqdm  # Fortschrittsbalken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe060ceb",
   "metadata": {},
   "source": [
    "## Get Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7b7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand_annotation = pd.read_csv(DATASET_PATHS / \"Hand_Annotation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "720b8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATHS / \"zw_personas.csv\")\n",
    "df_hand_annotation = pd.read_csv(DATASET_PATHS / \"Hand_Annotation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c34e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9121ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_sample['query'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e4f33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6025735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>time</th>\n",
       "      <th>ingredients_included</th>\n",
       "      <th>ingredients_avoid</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrates</th>\n",
       "      <th>fat</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you suggest flat-shapes recipes that do no...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you suggest libyan or british-columbian re...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you suggest non-alcoholic recipes that do ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you suggest octopus recipes that do not co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you suggest peruvian recipes that do not c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What reynolds-wrap dishes don't have cornstarc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>What somalian dishes can I make without chicke...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>What st-patricks-day dishes do not contain ing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What stocks dishes don't have dried navy beans?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>What wedding recipes can I cook without chicke...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  time  \\\n",
       "0   Can you suggest flat-shapes recipes that do no...   0.0   \n",
       "1   Can you suggest libyan or british-columbian re...   0.0   \n",
       "2   Can you suggest non-alcoholic recipes that do ...   0.0   \n",
       "3   Can you suggest octopus recipes that do not co...   0.0   \n",
       "4   Can you suggest peruvian recipes that do not c...   0.0   \n",
       "..                                                ...   ...   \n",
       "95  What reynolds-wrap dishes don't have cornstarc...   0.0   \n",
       "96  What somalian dishes can I make without chicke...   0.0   \n",
       "97  What st-patricks-day dishes do not contain ing...   0.0   \n",
       "98    What stocks dishes don't have dried navy beans?   0.0   \n",
       "99  What wedding recipes can I cook without chicke...   0.0   \n",
       "\n",
       "    ingredients_included  ingredients_avoid  cuisine  calories  carbohydrates  \\\n",
       "0                    0.0                2.0      0.0       0.0            0.0   \n",
       "1                    0.0                1.0      2.0       0.0            0.0   \n",
       "2                    0.0                2.0      0.0       0.0            0.0   \n",
       "3                    1.0                1.0      0.0       0.0            0.0   \n",
       "4                    0.0                1.0      1.0       0.0            1.0   \n",
       "..                   ...                ...      ...       ...            ...   \n",
       "95                   0.0                1.0      0.0       0.0            0.0   \n",
       "96                   0.0                1.0      1.0       0.0            0.0   \n",
       "97                   0.0                1.0      0.0       0.0            0.0   \n",
       "98                   1.0                1.0      0.0       0.0            0.0   \n",
       "99                   0.0                2.0      0.0       0.0            0.0   \n",
       "\n",
       "    fat  protein  \n",
       "0   0.0      0.0  \n",
       "1   0.0      0.0  \n",
       "2   0.0      0.0  \n",
       "3   1.0      0.0  \n",
       "4   0.0      0.0  \n",
       "..  ...      ...  \n",
       "95  1.0      0.0  \n",
       "96  0.0      0.0  \n",
       "97  0.0      0.0  \n",
       "98  0.0      0.0  \n",
       "99  0.0      0.0  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hand_annotation = df_hand_annotation.fillna(0)\n",
    "df_hand_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d8bec",
   "metadata": {},
   "source": [
    "## Information Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7d5fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def pipeline(model:ModelEnum, queries):\n",
    "    results = []\n",
    "    for query in tqdm(queries, desc=model.name):\n",
    "        information_extracted = extract_information(query, model)\n",
    "        results.append({\"query\": query, model.name: information_extracted})\n",
    "    \n",
    "    dataframe = pd.DataFrame(results)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6079f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLAMA:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLAMA: 100%|██████████| 100/100 [02:34<00:00,  1.54s/it]\n",
      "Gemini: 100%|██████████| 100/100 [01:56<00:00,  1.16s/it]\n",
      "OpenAI: 100%|██████████| 100/100 [02:56<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "models = [ModelEnum.LLAMA, ModelEnum.Gemini, ModelEnum.OpenAI]\n",
    "dfs = [pipeline(model, queries) for model in models]\n",
    "\n",
    "# alle DataFrames zusammenführen über die Spalte \"query\"\n",
    "final_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    final_df = pd.merge(final_df, df, on=\"query\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd4760",
   "metadata": {},
   "source": [
    "## Create Annotation csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbccd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Annotation.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c14c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(DATASET_PATHS / \"Annotation.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e592bd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e840f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO fuege human hinzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701487f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "model_list = [\"LLAMA\", \"Gemini\", \"OpenAI\"]\n",
    "for col in model_list:\n",
    "    final_df[col] = final_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2c186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b7f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angenommen deine Modelle heißen so:\n",
    "model_list = [\"LLAMA\", \"Gemini\", \"OpenAI\"]\n",
    "\n",
    "# Und deine Felder:\n",
    "fields = [\"time\", \"ingredients_included\", \"ingredients_avoid\", \"cuisine\", \"calories\"]\n",
    "\n",
    "# Für jede Modell/Feld-Kombination eine eigene Spalte erstellen:\n",
    "for model in model_list:\n",
    "    for field in fields:\n",
    "        final_df[f\"{model}_{field}\"] = final_df[model].apply(lambda d: len(d.get(field)) if isinstance(d, dict) else None)\n",
    "\n",
    "\n",
    "for model in model_list:\n",
    "    final_df[f\"{model}_cuisine\"] = final_df[f\"{model}_cuisine\"].apply(\n",
    "        lambda d: d if (isinstance(d, (int, float)) and d <= 2) else 0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d612528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand_annotation = df_hand_annotation.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3986a",
   "metadata": {},
   "source": [
    "## Create Groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "050c730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in fields:\n",
    "    final_df[f\"hand_{field}\"] = df_hand_annotation[field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93c72f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: Majority Vote (2-von-3). Bei 3 verschiedenen Werten -> NaN.\n",
    "def majority_vote(values, tie_break=None):\n",
    "    \"\"\"\n",
    "    values: Iterable (z.B. 3 Werte von LLAMA/Gemini/OpenAI)\n",
    "    tie_break: None | \"median\"\n",
    "        - None   -> bei 3 versch. Werten NaN\n",
    "        - median -> bei 3 versch. Werten Median (für ordinale Felder sinnvoll)\n",
    "    \"\"\"\n",
    "    vals = [v for v in values if pd.notna(v)]\n",
    "    if len(vals) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    vc = pd.Series(vals).value_counts()\n",
    "    if vc.iloc[0] >= 2:\n",
    "        # klare Mehrheit\n",
    "        return vc.index[0]\n",
    "\n",
    "    # alle drei verschieden -> optionaler Tie-Breaker\n",
    "    if tie_break == \"median\":\n",
    "        # für ordinale Felder (z.B. time/calories) oft sinnvoll\n",
    "        return float(np.median(vals))\n",
    "    return np.nan\n",
    "\n",
    "# Optional: Für welche Felder willst du bei 3 verschiedenen Werten den Median erzwingen?\n",
    "# (Ordinale Felder: time, calories) – kannst du anpassen oder leer lassen.\n",
    "median_tie_fields = {\"time\", \"calories\"}\n",
    "gt_list = model_list\n",
    "gt_list.append(\"hand\")\n",
    "gt_list.remove(\"Gemini\")\n",
    "# --- Ground-Truth-Spalten erzeugen\n",
    "for f in fields:\n",
    "    cols = [f\"{m}_{f}\" for m in gt_list]\n",
    "    tb = \"median\" if f in median_tie_fields else None\n",
    "    final_df[f\"gt_{f}\"] = final_df[cols].apply(lambda r: majority_vote(r.values, tie_break=tb), axis=1)\n",
    "\n",
    "# (Optional) Wenn du sicherstellen willst, dass cuisine strikt binär bleibt:\n",
    "# final_df[\"gt_cuisine\"] = final_df[\"gt_cuisine\"].apply(lambda x: 1.0 if x == 1 else (0.0 if x == 0 else np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aec671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69c3550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def _field_matrix_from_length_cols(df: pd.DataFrame, field: str, model_list):\n",
    "    \"\"\"\n",
    "    Holt die Ratings (Längen) für ein Feld als Matrix mit shape (n_items, n_rater),\n",
    "    wirft Zeilen mit NaN in irgendeinem Rater raus und gibt auch die verwendeten Kategorien zurück.\n",
    "    \"\"\"\n",
    "    cols = [f\"{m}_{field}\" for m in model_list]\n",
    "    sub = df[cols].copy()\n",
    "    sub = sub.dropna(axis=0, how=\"any\")  # nur vollständige Zeilen\n",
    "    if sub.empty:\n",
    "        return None, None, None\n",
    "    # in int konvertieren (falls float)\n",
    "    sub = sub.astype(int)\n",
    "    # Kategorien (über alle Items/Rater)\n",
    "    cats = sorted(pd.unique(sub.values.ravel()))\n",
    "    return sub.values, cats, cols\n",
    "\n",
    "def fleiss_kappa_from_length_cols(df: pd.DataFrame, field: str, model_list):\n",
    "    \"\"\"\n",
    "    Fleiss’ κ über Längenkategorien aus bereits flachen Spalten {Model}_{field}.\n",
    "    \"\"\"\n",
    "    M, cats, _ = _field_matrix_from_length_cols(df, field, model_list)\n",
    "    if M is None:\n",
    "        return np.nan\n",
    "    # Häufigkeitstabelle je Item: counts pro Kategorie\n",
    "    table = []\n",
    "    for row in M:\n",
    "        cnt = Counter(row)\n",
    "        table.append([cnt.get(c, 0) for c in cats])\n",
    "    freq = np.asarray(table)\n",
    "    # Sicherheit: jede Zeile sollte genau m Ratings haben\n",
    "    if not np.all(freq.sum(axis=1) == len(model_list)):\n",
    "        return np.nan\n",
    "    val = fleiss_kappa(freq)\n",
    "    try:\n",
    "        return float(val)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def pairwise_cohen_matrix_from_length_cols(df: pd.DataFrame, field: str, model_list, weights=None):\n",
    "    \"\"\"\n",
    "    Paarweise Cohen-κ-Matrix (n×n) für ein Feld aus {Model}_{field}.\n",
    "    \"\"\"\n",
    "    M, cats, cols = _field_matrix_from_length_cols(df, field, model_list)\n",
    "    if M is None:\n",
    "        return pd.DataFrame(np.nan, index=model_list, columns=model_list)\n",
    "    n = len(model_list)\n",
    "    mat = pd.DataFrame(np.nan, index=model_list, columns=model_list, dtype=float)\n",
    "    np.fill_diagonal(mat.values, 1.0)\n",
    "    for i, j in combinations(range(n), 2):\n",
    "        a = M[:, i]\n",
    "        b = M[:, j]\n",
    "        v = cohen_kappa_score(a, b, weights=weights)\n",
    "        mat.iloc[i, j] = v\n",
    "        mat.iloc[j, i] = v\n",
    "    return mat\n",
    "\n",
    "def kappa_per_field_and_overall_from_lengths(\n",
    "    df: pd.DataFrame,\n",
    "    fields=(\"ingredients_included\",\"ingredients_avoid\",\"cuisine\",\"calories\",\"time\"),\n",
    "    model_list=(\"LLAMA\",\"Gemini\",\"OpenAI\"),\n",
    "):\n",
    "    per_field = {}\n",
    "    # Für die paarweisen Overalls akkumulieren wir (Summe, Anzahl) getrennt\n",
    "    pairwise_acc = {\n",
    "        \"unweighted\": pd.DataFrame(0.0, index=model_list, columns=model_list),\n",
    "        \"linear\":     pd.DataFrame(0.0, index=model_list, columns=model_list),\n",
    "        \"quadratic\":  pd.DataFrame(0.0, index=model_list, columns=model_list),\n",
    "        \"_counts\":    pd.DataFrame(0,   index=model_list, columns=model_list, dtype=int),\n",
    "    }\n",
    "\n",
    "    for f in fields:\n",
    "        # Fleiss\n",
    "        fl = fleiss_kappa_from_length_cols(df, f, model_list)\n",
    "        # Paarweise Matrizen\n",
    "        M_unw  = pairwise_cohen_matrix_from_length_cols(df, f, model_list, weights=None)\n",
    "        M_lin  = pairwise_cohen_matrix_from_length_cols(df, f, model_list, weights=\"linear\")\n",
    "        M_quad = pairwise_cohen_matrix_from_length_cols(df, f, model_list, weights=\"quadratic\")\n",
    "\n",
    "        # Feld-Zusammenfassung als Mittel über Off-Diagonal-Paare\n",
    "        def offdiag_mean(M):\n",
    "            vals = []\n",
    "            for i, j in combinations(range(len(model_list)), 2):\n",
    "                v = M.iloc[i, j]\n",
    "                if pd.notna(v):\n",
    "                    vals.append(v)\n",
    "            return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "        per_field[f] = {\n",
    "            \"fleiss\": fl,\n",
    "            \"cohen_unweighted_mean\": offdiag_mean(M_unw),\n",
    "            \"cohen_linear_mean\": offdiag_mean(M_lin),\n",
    "            \"cohen_quadratic_mean\": offdiag_mean(M_quad),\n",
    "            \"pairwise_unweighted\": M_unw,\n",
    "            \"pairwise_linear\": M_lin,\n",
    "            \"pairwise_quadratic\": M_quad,\n",
    "        }\n",
    "\n",
    "        # Für Overall paarweise akkumulieren\n",
    "        for A, B in combinations(model_list, 2):\n",
    "            for key, M in [(\"unweighted\", M_unw), (\"linear\", M_lin), (\"quadratic\", M_quad)]:\n",
    "                v = M.loc[A, B]\n",
    "                if pd.notna(v):\n",
    "                    pairwise_acc[key].loc[A, B] += v\n",
    "                    pairwise_acc[key].loc[B, A] += v\n",
    "                    pairwise_acc[\"_counts\"].loc[A, B] += 1\n",
    "                    pairwise_acc[\"_counts\"].loc[B, A] += 1\n",
    "\n",
    "    # Overall: Macro-Average über Felder (nicht paarweise)\n",
    "    def avg_over_fields(key):\n",
    "        vals = [per_field[f][key] for f in fields if pd.notna(per_field[f][key])]\n",
    "        return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "    overall_macro = {\n",
    "        \"overall_fleiss\": avg_over_fields(\"fleiss\"),\n",
    "        \"overall_cohen_unweighted_mean\": avg_over_fields(\"cohen_unweighted_mean\"),\n",
    "        \"overall_cohen_linear_mean\":     avg_over_fields(\"cohen_linear_mean\"),\n",
    "        \"overall_cohen_quadratic_mean\":  avg_over_fields(\"cohen_quadratic_mean\"),\n",
    "    }\n",
    "\n",
    "    # Paarweise Overalls: Mittel über Felder\n",
    "    counts = pairwise_acc[\"_counts\"].replace(0, np.nan)\n",
    "    pairwise_overall = {}\n",
    "    for key in (\"unweighted\", \"linear\", \"quadratic\"):\n",
    "        M = pairwise_acc[key] / counts\n",
    "        # Diagonale = 1\n",
    "        np.fill_diagonal(M.values, 1.0)\n",
    "        pairwise_overall[key] = M\n",
    "\n",
    "    return per_field, overall_macro, pairwise_overall\n",
    "\n",
    "# ===== Ausführung / Beispiel =====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9e8cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def _field_matrix_from_length_cols(df: pd.DataFrame, field: str, model_list):\n",
    "    \"\"\"\n",
    "    Holt die Ratings (Längen) für ein Feld als Matrix shape (n_items, n_rater),\n",
    "    wirft Zeilen mit NaN raus, rundet sauber auf Integer und gibt die verdichteten\n",
    "    Kategorien (0..K-1) zurück, plus die Spaltennamen.\n",
    "    \"\"\"\n",
    "    cols = [f\"{m}_{field}\" for m in model_list]\n",
    "    sub = df[cols].copy()\n",
    "    sub = sub.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=0, how=\"any\")\n",
    "    if sub.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    # sauber runden (statt floor), dann in int\n",
    "    sub = sub.round().astype(int)\n",
    "\n",
    "    # Feldweites Kategorien-Set und Rangabbildung (verdichtet auf 0..K-1)\n",
    "    cats_orig = sorted(pd.unique(sub.values.ravel()))\n",
    "    rank_map = {c: i for i, c in enumerate(cats_orig)}\n",
    "    sub_rank = sub.replace(rank_map)\n",
    "\n",
    "    cats_dense = list(range(len(cats_orig)))  # 0..K-1\n",
    "    return sub_rank.values, cats_dense, cols\n",
    "\n",
    "def fleiss_kappa_from_length_cols(df: pd.DataFrame, field: str, model_list):\n",
    "    \"\"\"\n",
    "    Fleiss’ κ über Längenkategorien (verdichtete Ränge).\n",
    "    \"\"\"\n",
    "    M, cats, _ = _field_matrix_from_length_cols(df, field, model_list)\n",
    "    if M is None or len(cats) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    # Häufigkeiten pro Item/Kategorie\n",
    "    table = []\n",
    "    for row in M:\n",
    "        cnt = Counter(row)\n",
    "        table.append([cnt.get(c, 0) for c in cats])\n",
    "    freq = np.asarray(table, dtype=int)\n",
    "\n",
    "    # Sicherheit: jede Zeile = #Rater\n",
    "    if not np.all(freq.sum(axis=1) == len(model_list)):\n",
    "        return np.nan\n",
    "\n",
    "    val = fleiss_kappa(freq)  # method=\"fleiss\" ist Default\n",
    "    try:\n",
    "        return float(val)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def pairwise_cohen_matrix_from_length_cols(df: pd.DataFrame, field: str, model_list, weights=None):\n",
    "    \"\"\"\n",
    "    Paarweise Cohen-κ-Matrix (n×n) für ein Feld (verdichtete Ränge + feste Labels).\n",
    "    \"\"\"\n",
    "    M, cats, cols = _field_matrix_from_length_cols(df, field, model_list)\n",
    "    if M is None or len(cats) < 2:\n",
    "        return pd.DataFrame(np.nan, index=model_list, columns=model_list)\n",
    "\n",
    "    n = len(model_list)\n",
    "    mat = pd.DataFrame(np.nan, index=model_list, columns=model_list, dtype=float)\n",
    "\n",
    "    for i, j in combinations(range(n), 2):\n",
    "        a = M[:, i]\n",
    "        b = M[:, j]\n",
    "        # ganz wichtig: fixes, feldweites Labels-Set!\n",
    "        v = cohen_kappa_score(a, b, weights=weights, labels=cats)\n",
    "        mat.iloc[i, j] = v\n",
    "        mat.iloc[j, i] = v\n",
    "\n",
    "    # wenn du 1.0 auf der Diagonalen willst:\n",
    "    # np.fill_diagonal(mat.values, 1.0)\n",
    "    return mat\n",
    "\n",
    "def kappa_per_field_and_overall_from_lengths(\n",
    "    df: pd.DataFrame,\n",
    "    fields=(\"ingredients_included\",\"ingredients_avoid\",\"cuisine\",\"calories\",\"time\"),\n",
    "    model_list=(\"LLAMA\",\"Gemini\",\"OpenAI\"),\n",
    "):\n",
    "    per_field = {}\n",
    "    # Akkumulatoren für paarweise Overalls\n",
    "    pairwise_acc = {\n",
    "        \"unweighted\": pd.DataFrame(0.0, index=model_list, columns=model_list),\n",
    "        \"linear\":     pd.DataFrame(0.0, index=model_list, columns=model_list),\n",
    "        \"quadratic\":  pd.DataFrame(0.0, index=model_list, columns=model_list),\n",
    "        \"_counts\":    pd.DataFrame(0,   index=model_list, columns=model_list, dtype=int),\n",
    "    }\n",
    "\n",
    "    for f in fields:\n",
    "        fl = fleiss_kappa_from_length_cols(df, f, model_list)\n",
    "        M_unw  = pairwise_cohen_matrix_from_length_cols(df, f, model_list, weights=None)\n",
    "        M_lin  = pairwise_cohen_matrix_from_length_cols(df, f, model_list, weights=\"linear\")\n",
    "        M_quad = pairwise_cohen_matrix_from_length_cols(df, f, model_list, weights=\"quadratic\")\n",
    "\n",
    "        def offdiag_mean(M):\n",
    "            vals = []\n",
    "            for i, j in combinations(range(len(model_list)), 2):\n",
    "                v = M.iloc[i, j]\n",
    "                if pd.notna(v):\n",
    "                    vals.append(v)\n",
    "            return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "        per_field[f] = {\n",
    "            \"fleiss\": fl,\n",
    "            \"cohen_unweighted_mean\": offdiag_mean(M_unw),\n",
    "            \"cohen_linear_mean\":     offdiag_mean(M_lin),\n",
    "            \"cohen_quadratic_mean\":  offdiag_mean(M_quad),\n",
    "            \"pairwise_unweighted\":   M_unw,\n",
    "            \"pairwise_linear\":       M_lin,\n",
    "            \"pairwise_quadratic\":    M_quad,\n",
    "        }\n",
    "\n",
    "        # Overall-Akkumulation (nur Off-Diagonale)\n",
    "        for A, B in combinations(model_list, 2):\n",
    "            for key, M in [(\"unweighted\", M_unw), (\"linear\", M_lin), (\"quadratic\", M_quad)]:\n",
    "                v = M.loc[A, B]\n",
    "                if pd.notna(v):\n",
    "                    pairwise_acc[key].loc[A, B] += v\n",
    "                    pairwise_acc[key].loc[B, A] += v\n",
    "                    pairwise_acc[\"_counts\"].loc[A, B] += 1\n",
    "                    pairwise_acc[\"_counts\"].loc[B, A] += 1\n",
    "\n",
    "    def avg_over_fields(key):\n",
    "        vals = [per_field[f][key] for f in fields if pd.notna(per_field[f][key])]\n",
    "        return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "    overall_macro = {\n",
    "        \"overall_fleiss\":                    avg_over_fields(\"fleiss\"),\n",
    "        \"overall_cohen_unweighted_mean\":     avg_over_fields(\"cohen_unweighted_mean\"),\n",
    "        \"overall_cohen_linear_mean\":         avg_over_fields(\"cohen_linear_mean\"),\n",
    "        \"overall_cohen_quadratic_mean\":      avg_over_fields(\"cohen_quadratic_mean\"),\n",
    "    }\n",
    "\n",
    "    # Paarweise Overalls: Mittel über Felder (Diagonale optional NaN oder 1.0)\n",
    "    counts = pairwise_acc[\"_counts\"].replace(0, np.nan)\n",
    "    pairwise_overall = {}\n",
    "    for key in (\"unweighted\", \"linear\", \"quadratic\"):\n",
    "        M = pairwise_acc[key] / counts\n",
    "        # wenn du 1.0 auf Diagonale willst: np.fill_diagonal(M.values, 1.0)\n",
    "        pairwise_overall[key] = M\n",
    "\n",
    "    return per_field, overall_macro, pairwise_overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac30a061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa pro Feld:\n",
      "\n",
      "• ingredients_included\n",
      "  Fleiss’ κ:                 0.693\n",
      "  Cohen (ungew.):                0.692\n",
      "  Cohen (linear):                0.681\n",
      "  Cohen (quadr.):                0.664\n",
      "\n",
      "• ingredients_avoid\n",
      "  Fleiss’ κ:                 0.637\n",
      "  Cohen (ungew.):                0.644\n",
      "  Cohen (linear):                0.624\n",
      "  Cohen (quadr.):                0.605\n",
      "\n",
      "• cuisine\n",
      "  Fleiss’ κ:                 0.578\n",
      "  Cohen (ungew.):                0.580\n",
      "  Cohen (linear):                0.553\n",
      "  Cohen (quadr.):                0.525\n",
      "\n",
      "• calories\n",
      "  Fleiss’ κ: NaN\n",
      "  Cohen (ungew.): NaN\n",
      "  Cohen (linear): NaN\n",
      "  Cohen (quadr.): NaN\n",
      "\n",
      "Overall (Macro über Felder):\n",
      "  overall_fleiss: 0.636\n",
      "  overall_cohen_unweighted_mean: 0.639\n",
      "  overall_cohen_linear_mean: 0.620\n",
      "  overall_cohen_quadratic_mean: 0.598\n"
     ]
    }
   ],
   "source": [
    "fields = (\"ingredients_included\",\"ingredients_avoid\",\"cuisine\",\"calories\")\n",
    "models = (\"LLAMA\",\"Gemini\",\"OpenAI\",\"gt\", \"hand\")\n",
    "\n",
    "per_field, overall_macro, pairwise_overall = kappa_per_field_and_overall_from_lengths(final_df, fields, models)\n",
    "\n",
    "# Ausgabe (kurz)\n",
    "print(\"Kappa pro Feld:\")\n",
    "for f, rec in per_field.items():\n",
    "    print(f\"\\n• {f}\")\n",
    "    print(f\"  Fleiss’ κ:                 {rec['fleiss']:.3f}\" if pd.notna(rec['fleiss']) else \"  Fleiss’ κ: NaN\")\n",
    "    for name, key in [(\"Cohen (ungew.)\", \"cohen_unweighted_mean\"),\n",
    "                      (\"Cohen (linear)\", \"cohen_linear_mean\"),\n",
    "                      (\"Cohen (quadr.)\", \"cohen_quadratic_mean\")]:\n",
    "        v = rec[key]\n",
    "        print(f\"  {name}:                {v:.3f}\" if pd.notna(v) else f\"  {name}: NaN\")\n",
    "\n",
    "print(\"\\nOverall (Macro über Felder):\")\n",
    "for k, v in overall_macro.items():\n",
    "    print(f\"  {k}: {v:.3f}\" if pd.notna(v) else f\"  {k}: NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c604ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item-gewichtetes paarweises κ (ungewichtet):\n",
      "        LLAMA  Gemini  OpenAI     gt   hand\n",
      "LLAMA     NaN   0.952   0.962  0.988  0.154\n",
      "Gemini  0.952     NaN   0.961  0.951  0.149\n",
      "OpenAI  0.962   0.961     NaN  0.974  0.141\n",
      "gt      0.988   0.951   0.974    NaN  0.163\n",
      "hand    0.154   0.149   0.141  0.163    NaN\n"
     ]
    }
   ],
   "source": [
    "def _field_item_count(df, field, model_list):\n",
    "    cols = [f\"{m}_{field}\" for m in model_list]\n",
    "    sub = df[cols].apply(pd.to_numeric, errors=\"coerce\").dropna(axis=0, how=\"any\")\n",
    "    return len(sub)\n",
    "\n",
    "def pairwise_overall_item_weighted(df, fields, model_list, weights=None):\n",
    "    \"\"\"\n",
    "    Aggregiert paarweise Cohen-κ über Felder, gewichtet nach #Items pro Feld.\n",
    "    Entspricht inhaltlich deiner „Item-gewichteten“ Auswertung – nur paarweise als Matrix.\n",
    "    \"\"\"\n",
    "    # sammle pro Feld: paarweise Matrix + Gewicht n_f\n",
    "    mats, weights_list = [], []\n",
    "    for f in fields:\n",
    "        M, cats, _ = _field_matrix_from_length_cols(df, f, model_list)\n",
    "        if M is None or len(cats) < 2:\n",
    "            continue\n",
    "        n_f = _field_item_count(df, f, model_list)\n",
    "        if n_f == 0:\n",
    "            continue\n",
    "        # paarweise Matrix für dieses Feld\n",
    "        n = len(model_list)\n",
    "        mat_f = pd.DataFrame(np.nan, index=model_list, columns=model_list, dtype=float)\n",
    "        for i, j in combinations(range(n), 2):\n",
    "            a, b = M[:, i], M[:, j]\n",
    "            v = cohen_kappa_score(a, b, weights=weights, labels=cats)\n",
    "            mat_f.iloc[i, j] = v\n",
    "            mat_f.iloc[j, i] = v\n",
    "        mats.append(mat_f)\n",
    "        weights_list.append(n_f)\n",
    "\n",
    "    if not mats:\n",
    "        return pd.DataFrame(np.nan, index=model_list, columns=model_list, dtype=float)\n",
    "\n",
    "    # gewichteter Durchschnitt (elementweise)\n",
    "    W = float(np.sum(weights_list))\n",
    "    out = pd.DataFrame(0.0, index=model_list, columns=model_list, dtype=float)\n",
    "    wsum = pd.DataFrame(0.0, index=model_list, columns=model_list, dtype=float)\n",
    "    for mat_f, w in zip(mats, weights_list):\n",
    "        mask = mat_f.notna()\n",
    "        out = out.add(mat_f.fillna(0.0) * w, fill_value=0.0)\n",
    "        wsum = wsum.add(mask.astype(float) * w, fill_value=0.0)\n",
    "    out = out / wsum.replace(0.0, np.nan)\n",
    "    # Optional: Diagonale setzen\n",
    "    # np.fill_diagonal(out.values, 1.0)\n",
    "    return out\n",
    "pw_unw_item = pairwise_overall_item_weighted(final_df, fields, models, weights=None)\n",
    "pw_lin_item = pairwise_overall_item_weighted(final_df, fields, models, weights=\"linear\")\n",
    "pw_quad_item = pairwise_overall_item_weighted(final_df, fields, models, weights=\"quadratic\")\n",
    "\n",
    "print(\"\\nItem-gewichtetes paarweises κ (ungewichtet):\")\n",
    "print(pw_unw_item.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7505cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items je Feld: {'ingredients_included': 99, 'ingredients_avoid': 100, 'cuisine': 94, 'calories': 100}\n",
      "\n",
      "ingredients_included – paarweise κ (ungewichtet):\n",
      "        LLAMA  Gemini  OpenAI     gt   hand\n",
      "LLAMA     NaN   0.981   0.981  0.981  0.252\n",
      "Gemini  0.981     NaN   0.962  0.962  0.269\n",
      "OpenAI  0.981   0.962     NaN  1.000  0.269\n",
      "gt      0.981   0.962   1.000    NaN  0.269\n",
      "hand    0.252   0.269   0.269  0.269    NaN\n",
      "\n",
      "ingredients_avoid – paarweise κ (ungewichtet):\n",
      "        LLAMA  Gemini  OpenAI    gt  hand\n",
      "LLAMA     NaN    1.00    1.00  1.00  0.11\n",
      "Gemini   1.00     NaN    1.00  1.00  0.11\n",
      "OpenAI   1.00    1.00     NaN  1.00  0.11\n",
      "gt       1.00    1.00    1.00   NaN  0.11\n",
      "hand     0.11    0.11    0.11  0.11   NaN\n",
      "\n",
      "cuisine – paarweise κ (ungewichtet):\n",
      "        LLAMA  Gemini  OpenAI     gt   hand\n",
      "LLAMA     NaN   0.871   0.903  0.984  0.098\n",
      "Gemini  0.871     NaN   0.919  0.887  0.066\n",
      "OpenAI  0.903   0.919     NaN  0.919  0.041\n",
      "gt      0.984   0.887   0.919    NaN  0.109\n",
      "hand    0.098   0.066   0.041  0.109    NaN\n",
      "\n",
      "calories – paarweise κ (ungewichtet):\n",
      "        LLAMA  Gemini  OpenAI  gt  hand\n",
      "LLAMA     NaN     NaN     NaN NaN   NaN\n",
      "Gemini    NaN     NaN     NaN NaN   NaN\n",
      "OpenAI    NaN     NaN     NaN NaN   NaN\n",
      "gt        NaN     NaN     NaN NaN   NaN\n",
      "hand      NaN     NaN     NaN NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "N_per_field = {f: _field_item_count(final_df, f, models) for f in fields}\n",
    "print(\"Items je Feld:\", N_per_field)\n",
    "\n",
    "# Paarweise κ je Feld (ungewichtet), um „Problemfelder“ zu sehen:\n",
    "for f in fields:\n",
    "    M_unw = per_field[f][\"pairwise_unweighted\"]\n",
    "    print(f\"\\n{f} – paarweise κ (ungewichtet):\")\n",
    "    print(M_unw.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b6823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
