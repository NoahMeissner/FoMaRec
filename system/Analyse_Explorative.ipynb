{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecd545c",
   "metadata": {},
   "source": [
    "# Explorative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ddf3b",
   "metadata": {},
   "source": [
    "in diesem Skript werden die initialen Analysen gemacht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd399ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from foodrec.config.structure.dataset_enum import ModelEnum \n",
    "from foodrec.config.structure.paths import CONVERSATION, DATASET_PATHS\n",
    "from collections import Counter\n",
    "from foodrec.evaluation.reward_evaluation import routing_accuracy\n",
    "from analysis_helper.mean_rounds import calc_rounds\n",
    "from analysis_helper.query_analysis import calc_other_recommendation_parameters\n",
    "from analysis_helper.calc_routing_reward import get_reward_set, reward_average_calculation\n",
    "from analysis_helper.calc_path_length import calc_path_length\n",
    "from analysis_helper.most_common_path import most_common_path\n",
    "from analysis_helper.time import calc_mean_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb86f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_set = pd.read_csv(DATASET_PATHS / \"zw_personas.csv\")\n",
    "model = ModelEnum.Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6807fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(model_name):\n",
    "    return {\n",
    "        \"PATH_NO_BIASE\": CONVERSATION / model_name / \"no_biase\",\n",
    "        \"PATH_SYSTEM_BIASE\": CONVERSATION / model_name / \"system_biase\",\n",
    "        \"PATH_SEARCH_ENGINE\": CONVERSATION / ModelEnum.Gemini.name / \"search_engine\" / \"res_one.json\",\n",
    "        \"PATH_SEARCH_BIASE\": CONVERSATION / model_name / \"search_biase\" ,\n",
    "        \"PATH_BOTH\": CONVERSATION / model_name / \"both_biase\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6640c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_paths(ModelEnum.Gemini.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668581fb",
   "metadata": {},
   "source": [
    "## Deskriptive Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e9d9a",
   "metadata": {},
   "source": [
    "### Query Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a786ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_accuracy(df, model_name:ModelEnum):\n",
    "    paths = get_paths(str(ModelEnum.Gemini.name))    \n",
    "    print(10*\"-\"+\"PATH_NO_BIASE\"+10*\"-\")\n",
    "    calc_other_recommendation_parameters(df, paths[\"PATH_NO_BIASE\"],model_name )\n",
    "    print(10*\"-\"+\"PATH_SYSTEM_BIASE\"+10*\"-\")\n",
    "    calc_other_recommendation_parameters(df, paths[\"PATH_SYSTEM_BIASE\"],model_name )\n",
    "    print(10*\"-\"+\"PATH_SEARCH_ENGINE\"+10*\"-\")\n",
    "    calc_other_recommendation_parameters(df, paths[\"PATH_SEARCH_ENGINE\"], ModelEnum.Gemini ,Search_engine = True)\n",
    "    print(10*\"-\"+\"PATH_BOTH\"+10*\"-\")\n",
    "    calc_other_recommendation_parameters(df, paths[\"PATH_BOTH\"], model_name )\n",
    "    print(10*\"-\"+\"PATH_SEARCH_BIASE\"+10*\"-\")\n",
    "    calc_other_recommendation_parameters(df, paths[\"PATH_SEARCH_BIASE\"], model_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf7adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 22:27:43,072 - foodrec.data.load_ingredient_embeddings - INFO - EmbeddingLoader initialized with path: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:43,072 - foodrec.data.load_ingredient_embeddings - INFO - Starting embedding retrieval process...\n",
      "2025-09-13 22:27:43,072 - foodrec.data.load_ingredient_embeddings - INFO - ✓ Found existing embeddings file: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:43,073 - foodrec.data.load_ingredient_embeddings - INFO - Loading existing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------PATH_NO_BIASE----------\n",
      "####################Load Embeddings####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 22:27:47,047 - foodrec.data.load_ingredient_embeddings - INFO - EmbeddingLoader initialized with path: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:47,047 - foodrec.data.load_ingredient_embeddings - INFO - Starting embedding retrieval process...\n",
      "2025-09-13 22:27:47,048 - foodrec.data.load_ingredient_embeddings - INFO - ✓ Found existing embeddings file: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:47,048 - foodrec.data.load_ingredient_embeddings - INFO - Loading existing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like 0.58\n",
      " Avoid 0.9912280701754386\n",
      "Cuisine 0.9230769230769231\n",
      "Overall0.8314349977507872\n",
      "----------PATH_SYSTEM_BIASE----------\n",
      "####################Load Embeddings####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 22:27:48,563 - foodrec.data.load_ingredient_embeddings - INFO - EmbeddingLoader initialized with path: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:48,563 - foodrec.data.load_ingredient_embeddings - INFO - Starting embedding retrieval process...\n",
      "2025-09-13 22:27:48,563 - foodrec.data.load_ingredient_embeddings - INFO - ✓ Found existing embeddings file: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:48,564 - foodrec.data.load_ingredient_embeddings - INFO - Loading existing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like 0.5106382978723404\n",
      " Avoid 0.99\n",
      "Cuisine 0.8620689655172413\n",
      "Overall0.7875690877965272\n",
      "----------PATH_SEARCH_ENGINE----------\n",
      "####################Load Embeddings####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 22:27:50,136 - foodrec.data.load_ingredient_embeddings - INFO - EmbeddingLoader initialized with path: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:50,136 - foodrec.data.load_ingredient_embeddings - INFO - Starting embedding retrieval process...\n",
      "2025-09-13 22:27:50,136 - foodrec.data.load_ingredient_embeddings - INFO - ✓ Found existing embeddings file: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:50,136 - foodrec.data.load_ingredient_embeddings - INFO - Loading existing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like 0.6274509803921569\n",
      " Avoid 0.9910714285714286\n",
      "Cuisine 0.7936507936507936\n",
      "Overall0.8040577342047931\n",
      "----------PATH_BOTH----------\n",
      "####################Load Embeddings####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 22:27:51,635 - foodrec.data.load_ingredient_embeddings - INFO - EmbeddingLoader initialized with path: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:51,636 - foodrec.data.load_ingredient_embeddings - INFO - Starting embedding retrieval process...\n",
      "2025-09-13 22:27:51,636 - foodrec.data.load_ingredient_embeddings - INFO - ✓ Found existing embeddings file: /Users/noah/Documents/github/MultiAgentBiase/system/foodrec/config/dataset/ingredient_embeddings/ingredient_embeddings_ALL_RECIPE.csv\n",
      "2025-09-13 22:27:51,636 - foodrec.data.load_ingredient_embeddings - INFO - Loading existing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like 0.5625\n",
      " Avoid 0.991304347826087\n",
      "Cuisine 0.8769230769230769\n",
      "Overall0.810242474916388\n",
      "----------PATH_SEARCH_BIASE----------\n",
      "####################Load Embeddings####################\n",
      "Like 0.4375\n",
      " Avoid 1.0\n",
      "Cuisine 0.8524590163934426\n",
      "Overall0.7633196721311476\n"
     ]
    }
   ],
   "source": [
    "recommendation_accuracy(query_set, ModelEnum.Gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934cd79",
   "metadata": {},
   "source": [
    "### All Recipe Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc9594",
   "metadata": {},
   "source": [
    "## Mas Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78303261",
   "metadata": {},
   "source": [
    "### Mean Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9d5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_rounds(df, paths, model_name: ModelEnum):\n",
    "    def calc_median_rounds(df, model:ModelEnum, Path):\n",
    "        ls = []\n",
    "        for index, row in df.iterrows():\n",
    "            persona_id = row[\"id\"]\n",
    "            query = row[\"query\"]\n",
    "            ls.append(calc_rounds(persona_id=persona_id, query=query, model=model, Path=Path))\n",
    "        return np.mean(ls)\n",
    "    print(\"Mean Rounds No Biase:\", calc_median_rounds(df, model_name, paths['PATH_NO_BIASE']))\n",
    "    print(\"Mean Rounds System Biase:\", calc_median_rounds(df, model_name, paths['PATH_SYSTEM_BIASE']))\n",
    "    print(\"Mean Search Biase:\", calc_median_rounds(df, model_name, paths['PATH_SEARCH_BIASE']))\n",
    "    print(\"Mean Both Biase:\", calc_median_rounds(df, model_name, paths['PATH_BOTH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce6ce7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rounds No Biase: 1.67\n",
      "Mean Rounds System Biase: 2.43\n",
      "Mean Search Biase: 1.84\n",
      "Mean Both Biase: 2.38\n"
     ]
    }
   ],
   "source": [
    "calc_mean_rounds(query_set, paths=paths, model_name=ModelEnum.Gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcfeaaf",
   "metadata": {},
   "source": [
    "### Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e77ec7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reward(query_set, paths, model_name: ModelEnum):\n",
    "    reward_system_biase = get_reward_set(query_set, model_name, paths['PATH_SYSTEM_BIASE'])\n",
    "    reward_system_no = get_reward_set(query_set, model_name, paths['PATH_NO_BIASE'])\n",
    "    reward_search_biase = get_reward_set(query_set, model_name, paths['PATH_SEARCH_BIASE'])\n",
    "    reward_both = get_reward_set(query_set, model_name, paths['PATH_BOTH'])\n",
    "    print(f\"Durchschnittlicher Score für System Biase: {reward_average_calculation(reward_system_biase)}\")\n",
    "\n",
    "    print(f\"Durchschnittlicher Score fuer No Biase: {reward_average_calculation(reward_system_no)}\")\n",
    "    \n",
    "    print(f\"Durchschnittlicher Score für Search Biase: {reward_average_calculation(reward_search_biase)}\")\n",
    "    \n",
    "    print(f\"Durchschnittlicher Score für Both Biase: {reward_average_calculation(reward_both)}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d45c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher Score für System Biase: Score: 0.5148 bei gamma=1, normalize=True\n",
      "Durchschnittlicher Score fuer No Biase: Score: 0.4495 bei gamma=1, normalize=True\n",
      "Durchschnittlicher Score für Search Biase: Score: 0.4533 bei gamma=1, normalize=True\n",
      "Durchschnittlicher Score für Both Biase: Score: 0.5175 bei gamma=1, normalize=True\n"
     ]
    }
   ],
   "source": [
    "calc_reward(query_set=query_set, paths=paths, model_name=ModelEnum.Gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa739f2d",
   "metadata": {},
   "source": [
    "### Average Path Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a9b33",
   "metadata": {},
   "source": [
    "### Routing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_average_path_length(df, paths, model_name: ModelEnum):\n",
    "    def calc_median_path_length(df, model:ModelEnum, Path):\n",
    "        ls = []\n",
    "        for index, row in df.iterrows():\n",
    "            persona_id = row[\"id\"]\n",
    "            query = row[\"query\"]\n",
    "            ls.append(calc_path_length(persona_id=persona_id, query=query, model=model, path=Path))\n",
    "        return np.mean(ls)\n",
    "\n",
    "    print(\"Mean Path Length No Biase:\", calc_median_path_length(df, model_name, paths['PATH_NO_BIASE']))\n",
    "    print(\"Mean Path Length Biase:\", calc_median_path_length(df, model_name, paths['PATH_SYSTEM_BIASE']))\n",
    "    print(\"Mean Path Search Biase:\", calc_median_path_length(df, model_name, paths['PATH_SEARCH_BIASE']))\n",
    "    print(\"Mean Path Both Biase:\", calc_median_path_length(df, model_name, paths['PATH_BOTH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0932772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Path Length No Biase: 7.07\n",
      "Mean Path Length Biase: 9.27\n",
      "Mean Path Search Biase: 7.51\n",
      "Mean Path Both Biase: 9.07\n"
     ]
    }
   ],
   "source": [
    "calc_average_path_length(df=query_set,paths=paths, model_name=ModelEnum.Gemini)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd89636",
   "metadata": {},
   "source": [
    "### Routing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d1489df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_routing_accuracy(query_set, paths, model_name: ModelEnum):\n",
    "    def routing_accuracy_calculation(reward_system):\n",
    "        scores = []\n",
    "        for i, episode in enumerate(reward_system, start=1):\n",
    "            score = routing_accuracy(episode)\n",
    "            scores.append(score)\n",
    "\n",
    "        # Optional: Gesamtauswertung\n",
    "        avg_score = np.mean(scores)\n",
    "        return f\"Score: {avg_score:.4f}\"\n",
    "    reward_system_biase = get_reward_set(query_set, model_name, paths['PATH_SYSTEM_BIASE'])\n",
    "    reward_system_no = get_reward_set(query_set, model_name, paths['PATH_NO_BIASE'])\n",
    "    reward_search_biase = get_reward_set(query_set, model_name, paths['PATH_SEARCH_BIASE'])\n",
    "    reward_both = get_reward_set(query_set, model_name, paths['PATH_BOTH'])\n",
    "\n",
    "    print(f\"Durchschnittlicher Score für System Biase: {routing_accuracy_calculation(reward_system_biase)}\")\n",
    "    print(f\"Durchschnittlicher Score fuer No Biase: {routing_accuracy_calculation(reward_system_no)}\")\n",
    "    print(f\"Durchschnittlicher Score für Search Biase: {routing_accuracy_calculation(reward_search_biase)}\")\n",
    "    print(f\"Durchschnittlicher Score fuer Both Biase: {routing_accuracy_calculation(reward_both)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ea69d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher Score für System Biase: Score: 0.7574\n",
      "Durchschnittlicher Score fuer No Biase: Score: 0.7248\n",
      "Durchschnittlicher Score für Search Biase: Score: 0.7267\n",
      "Durchschnittlicher Score fuer Both Biase: Score: 0.7588\n"
     ]
    }
   ],
   "source": [
    "calc_routing_accuracy(query_set=query_set,paths=paths, model_name=ModelEnum.Gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e690877",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_get_most_common_paths(df, paths, model_name: ModelEnum):\n",
    "    def calc_median_path_length(df, model:ModelEnum, Path):\n",
    "        ls = []\n",
    "        for index, row in df.iterrows():\n",
    "            persona_id = row[\"id\"]\n",
    "            query = row[\"query\"]\n",
    "            res = (most_common_path(persona_id=persona_id, query=query, model=model, Path=Path))\n",
    "            ls.append(\"->\".join(str(x) for x in res if x is not None))\n",
    "        return ls\n",
    "    \n",
    "    def calc_sum(df, model_name, path):\n",
    "        counts = Counter(calc_median_path_length(df, model=model_name, Path=path))\n",
    "        total = sum(counts.values()) or 1  # Schutz gegen Division durch 0\n",
    "        top = counts.most_common(5)\n",
    "        result = [\n",
    "            {\"path\": p, \"count\": c, \"percent\": round(c * 100.0 / total, 2)}\n",
    "            for p, c in top\n",
    "        ]\n",
    "        for i, item in enumerate(result, 1):\n",
    "            print(f\"{i}. {item['path']} — {item['count']}x ({item['percent']}%)\")\n",
    "    \n",
    "    print(10*\"-\"+\"No Biase\"+10*\"-\")\n",
    "    print(\"Mean Rounds No Biase:\", calc_sum(df, model_name, paths['PATH_NO_BIASE']))\n",
    "    print(10*\"-\"+\"PATH_SYSTEM_BIASE\"+10*\"-\")\n",
    "    print(\"Mean Rounds System Biase:\", calc_sum(df, model_name, paths['PATH_SYSTEM_BIASE']))\n",
    "    print(10*\"-\"+\"PATH_SEARCH_BIASE\"+10*\"-\")\n",
    "    print(\"Mean Search Biase:\", calc_sum(df, model_name, paths['PATH_SEARCH_BIASE']))\n",
    "    print(10*\"-\"+\"PATH_BOTH\"+10*\"-\")\n",
    "    print(\"Mean Both Biase:\", calc_sum(df, model_name, paths['PATH_BOTH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c477656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------No Biase----------\n",
      "1. IN->US->SE->IT->RE — 61x (61.0%)\n",
      "2. IN->US->SE->IT->RE->SE->IT->RE — 13x (13.0%)\n",
      "3. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE — 9x (9.0%)\n",
      "4. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE — 8x (8.0%)\n",
      "5.  — 4x (4.0%)\n",
      "Mean Rounds No Biase: None\n",
      "----------PATH_SYSTEM_BIASE----------\n",
      "1. IN->US->SE->IT->RE — 37x (37.0%)\n",
      "2. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE — 24x (24.0%)\n",
      "3. IN->US->SE->IT->RE->SE->IT->RE — 18x (18.0%)\n",
      "4. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE — 9x (9.0%)\n",
      "5.  — 4x (4.0%)\n",
      "Mean Rounds System Biase: None\n",
      "----------PATH_SEARCH_BIASE----------\n",
      "1. IN->US->SE->IT->RE — 52x (52.0%)\n",
      "2. IN->US->SE->IT->RE->SE->IT->RE — 20x (20.0%)\n",
      "3. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE — 12x (12.0%)\n",
      "4. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE — 4x (4.0%)\n",
      "5.  — 4x (4.0%)\n",
      "Mean Search Biase: None\n",
      "----------PATH_BOTH----------\n",
      "1. IN->US->SE->IT->RE — 40x (40.0%)\n",
      "2. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE->SE->IT->RE — 23x (23.0%)\n",
      "3. IN->US->SE->IT->RE->SE->IT->RE — 18x (18.0%)\n",
      "4. IN->US->SE->IT->RE->SE->IT->RE->SE->IT->RE — 10x (10.0%)\n",
      "5.  — 4x (4.0%)\n",
      "Mean Both Biase: None\n"
     ]
    }
   ],
   "source": [
    "calc_get_most_common_paths(query_set, paths,model_name=ModelEnum.Gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42da002",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f91c7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time No Biase: 40.16\n",
      "Mean Time System Biase: 51.25\n",
      "Mean Time Search Biase: 32.21\n",
      "Mean Both Biase: 36.93\n"
     ]
    }
   ],
   "source": [
    "calc_mean_time(query_set, paths=paths, model_name=ModelEnum.Gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
